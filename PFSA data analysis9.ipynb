{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "solid-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "import time\n",
    "from scipy.sparse.linalg import eigs\n",
    "from numpy.linalg import inv\n",
    "import sys\n",
    "from PFSA import PFSA\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-anthony",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid blue\"> </hr>\n",
    "\n",
    "## load the in-core and ex-core detector signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unknown-saturn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000001,)\n",
      "(1000000001,)\n"
     ]
    }
   ],
   "source": [
    "# import the in-core and ex-core detector signal\n",
    "Xn_IC = np.load(\"X_incore_normal.npz\")\n",
    "Xa_IC = np.load(\"X_incore_abnormal.npz\")\n",
    "\n",
    "print(Xn_IC.shape)\n",
    "print(Xa_IC.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-stewart",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid blue\"> </hr>\n",
    "\n",
    "## downsampling to fs = 100 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "widespread-benjamin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000000,)\n",
      "(100000000,)\n"
     ]
    }
   ],
   "source": [
    "Xn_IC =  Xn_IC[0:-1:10]\n",
    "Xa_IC =  Xa_IC[0:-1:10]\n",
    "print(Xn_IC.shape)\n",
    "print(Xa_IC.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-colonial",
   "metadata": {},
   "source": [
    "#### Define sliding window slicing,\n",
    "- __for newer numpy version, numpy.lib.stride_tricks.sliding_window_view is equivalent__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "federal-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_slicing(a, no_items, item_type=0):\n",
    "    \n",
    "    # credit to : https://stackoverflow.com/questions/62253105/which-datatypes-do-i-have-to-use-to-write-this-function-in-cython\n",
    "    \n",
    "    \"\"\"This method perfoms sliding window slicing of numpy arrays\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : numpy\n",
    "        An array to be slided in subarrays\n",
    "    no_items : int\n",
    "        Number of sliced arrays or elements in sliced arrays\n",
    "    item_type: int\n",
    "        Indicates if no_items is number of sliced arrays (item_type=0) or\n",
    "        number of elements in sliced array (item_type=1), by default 0\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    numpy\n",
    "        Sliced numpy array\n",
    "    \"\"\"\n",
    "    if item_type == 0:\n",
    "        no_slices = no_items\n",
    "        no_elements = len(a) + 1 - no_slices\n",
    "        if no_elements <=0:\n",
    "            raise ValueError('Sliding slicing not possible, no_items is larger than ' + str(len(a)))\n",
    "    else:\n",
    "        no_elements = no_items                \n",
    "        no_slices = len(a) - no_elements + 1\n",
    "        if no_slices <=0:\n",
    "            raise ValueError('Sliding slicing not possible, no_items is larger than ' + str(len(a)))\n",
    "\n",
    "    subarray_shape = a.shape[1:]\n",
    "    shape_cfg = (no_slices, no_elements) + subarray_shape\n",
    "    strides_cfg = (a.strides[0],) + a.strides\n",
    "    as_strided = np.lib.stride_tricks.as_strided #shorthand\n",
    "    return as_strided(a, shape=shape_cfg, strides=strides_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-oregon",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid blue\"> </hr>\n",
    "\n",
    "## preparing the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "known-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 100\n",
    "Ns = 100000000\n",
    "X_class1_train = Xn_IC[:int(Ns/2)] # use half of the time series as training set (normal)\n",
    "X_class2_train = Xa_IC[:int(Ns/2)] # usee half of thee time series as training set (abnormal)\n",
    "window = fs * 1000 # window size is 1000 seconds, correspondingly 1000 * 100 points\n",
    "sample_size = len(X_class1_train) // window # the number of samples in the training set\n",
    "\n",
    "X_class1_train = X_class1_train.reshape(sample_size, window) # reshape the training set (normal)\n",
    "X_class1_train = X_class1_train.reshape(*X_class1_train.shape, 1) # reshape the training set step 2 (normal)\n",
    "Y_class1_train = np.zeros(sample_size) # create the training set Ys (normal)\n",
    "\n",
    "X_class2_train = X_class2_train.reshape(sample_size, window) # reshape the training set (abnormal)\n",
    "X_class2_train = X_class2_train.reshape(*X_class2_train.shape, 1) # reshape the training set step 2 (abnormal)\n",
    "Y_class2_train = np.ones(sample_size) # create the training set Ys (abnormal)\n",
    "\n",
    "X_train = np.concatenate([X_class1_train, X_class2_train]) # prepare the training set X (combine the normal and abnormal together)\n",
    "Y_train = np.concatenate([Y_class1_train, Y_class2_train]) # prepare the training set Y\n",
    "\n",
    "X_test_class1 = Xn_IC[int(Ns/2):int(Ns/2)+int(Ns/100)] # only 10000 seconds are used for testing, no need to do all\n",
    "X_test_class2 = Xa_IC[int(Ns/2):int(Ns/2)+int(Ns/100)] # see above\n",
    "\n",
    "X_test = np.concatenate([X_test_class1, X_test_class2])\n",
    "X_test = sliding_window_slicing(X_test, fs*1000, 1) # window size is 1000 seconds, correspondingly 1000 * 100 points\n",
    "X_test = X_test[1::fs] # no need to test time point of sampling, instead test every seconds\n",
    "X_test = X_test.reshape(*X_test.shape, 1) # reshape the X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-eclipse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalization for all classes together\n",
      "get the same bounds for all classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xxc90/neutronNoise_paper/PFSA.py:452: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"determine_partitioning_bounds\" failed type inference due to: No implementation of function Function(<built-in function mul>) found for signature:\n",
      " \n",
      " >>> mul(int64, list(int64)<iv=None>)\n",
      " \n",
      "There are 12 candidate implementations:\n",
      "   - Of which 10 did not match due to:\n",
      "   Overload of function 'mul': File: <numerous>: Line N/A.\n",
      "     With argument(s): '(int64, list(int64)<iv=None>)':\n",
      "    No match.\n",
      "   - Of which 2 did not match due to:\n",
      "   Operator Overload in function 'mul': File: unknown: Line unknown.\n",
      "     With argument(s): '(int64, list(int64)<iv=None>)':\n",
      "    No match for registered cases:\n",
      "     * (int64, int64) -> int64\n",
      "     * (int64, uint64) -> int64\n",
      "     * (uint64, int64) -> int64\n",
      "     * (uint64, uint64) -> uint64\n",
      "     * (float32, float32) -> float32\n",
      "     * (float64, float64) -> float64\n",
      "     * (complex64, complex64) -> complex64\n",
      "     * (complex128, complex128) -> complex128\n",
      "\n",
      "During: typing of intrinsic-call at /home/xxc90/neutronNoise_paper/PFSA.py (471)\n",
      "\n",
      "File \"PFSA.py\", line 471:\n",
      "    def determine_partitioning_bounds(self, x, n):\n",
      "        <source elided>\n",
      "        Neach_section, extras = divmod(Ntotal, Nsections)\n",
      "        section_sizes = ([0] + extras * [Neach_section+1] +\n",
      "        ^\n",
      "\n",
      "  @numba.jit(boundscheck=True)\n",
      "/home/xxc90/neutronNoise_paper/PFSA.py:452: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"determine_partitioning_bounds\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"PFSA.py\", line 476:\n",
      "    def determine_partitioning_bounds(self, x, n):\n",
      "        <source elided>\n",
      "        bounds = []\n",
      "        for i in range(0, x_n):\n",
      "        ^\n",
      "\n",
      "  @numba.jit(boundscheck=True)\n",
      "/home/xxc90/.local/lib/python3.8/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"determine_partitioning_bounds\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"PFSA.py\", line 465:\n",
      "    def determine_partitioning_bounds(self, x, n):\n",
      "        <source elided>\n",
      "\n",
      "        x = x.copy()\n",
      "        ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/xxc90/.local/lib/python3.8/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"PFSA.py\", line 465:\n",
      "    def determine_partitioning_bounds(self, x, n):\n",
      "        <source elided>\n",
      "\n",
      "        x = x.copy()\n",
      "        ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/home/xxc90/neutronNoise_paper/PFSA.py:452: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"determine_partitioning_bounds\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /home/xxc90/neutronNoise_paper/PFSA.py (476)\n",
      "\n",
      "File \"PFSA.py\", line 476:\n",
      "    def determine_partitioning_bounds(self, x, n):\n",
      "        <source elided>\n",
      "        bounds = []\n",
      "        for i in range(0, x_n):\n",
      "        ^\n",
      "\n",
      "  @numba.jit(boundscheck=True)\n",
      "/home/xxc90/.local/lib/python3.8/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"determine_partitioning_bounds\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"PFSA.py\", line 476:\n",
      "    def determine_partitioning_bounds(self, x, n):\n",
      "        <source elided>\n",
      "        bounds = []\n",
      "        for i in range(0, x_n):\n",
      "        ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/xxc90/.local/lib/python3.8/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"PFSA.py\", line 476:\n",
      "    def determine_partitioning_bounds(self, x, n):\n",
      "        <source elided>\n",
      "        bounds = []\n",
      "        for i in range(0, x_n):\n",
      "        ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get symbols for all classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xxc90/neutronNoise_paper/PFSA.py:627: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"_ravel_index\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /home/xxc90/neutronNoise_paper/PFSA.py (629)\n",
      "\n",
      "File \"PFSA.py\", line 629:\n",
      "    def _ravel_index(self, x, dims):\n",
      "        (x_l, x_m, x_n) = x.shape\n",
      "        ^\n",
      "\n",
      "  @numba.jit(boundscheck=True)\n",
      "/home/xxc90/neutronNoise_paper/PFSA.py:627: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"_ravel_index\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"PFSA.py\", line 636:\n",
      "    def _ravel_index(self, x, dims):\n",
      "        <source elided>\n",
      "        # output is the index of the hypercube, in the above example case, return 1\n",
      "        for l in range(0, x_l):\n",
      "        ^\n",
      "\n",
      "  @numba.jit(boundscheck=True)\n",
      "/home/xxc90/.local/lib/python3.8/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"_ravel_index\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"PFSA.py\", line 629:\n",
      "    def _ravel_index(self, x, dims):\n",
      "        (x_l, x_m, x_n) = x.shape\n",
      "        ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/xxc90/.local/lib/python3.8/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"PFSA.py\", line 629:\n",
      "    def _ravel_index(self, x, dims):\n",
      "        (x_l, x_m, x_n) = x.shape\n",
      "        ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get states for all classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xxc90/neutronNoise_paper/PFSA.py:548: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"generate_states\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /home/xxc90/neutronNoise_paper/PFSA.py (553)\n",
      "\n",
      "File \"PFSA.py\", line 553:\n",
      "    def generate_states(self, x, depth, alphabet_size):\n",
      "        <source elided>\n",
      "        #   - columns are steps\n",
      "        x = x.copy()\n",
      "        ^\n",
      "\n",
      "  @numba.jit(boundscheck=True)\n",
      "/home/xxc90/neutronNoise_paper/PFSA.py:548: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"generate_states\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"PFSA.py\", line 558:\n",
      "    def generate_states(self, x, depth, alphabet_size):\n",
      "        <source elided>\n",
      "        else:\n",
      "            (x_m, x_n) = x.shape\n",
      "            ^\n",
      "\n",
      "  @numba.jit(boundscheck=True)\n",
      "/home/xxc90/.local/lib/python3.8/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"generate_states\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"PFSA.py\", line 553:\n",
      "    def generate_states(self, x, depth, alphabet_size):\n",
      "        <source elided>\n",
      "        #   - columns are steps\n",
      "        x = x.copy()\n",
      "        ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/xxc90/.local/lib/python3.8/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"PFSA.py\", line 553:\n",
      "    def generate_states(self, x, depth, alphabet_size):\n",
      "        <source elided>\n",
      "        #   - columns are steps\n",
      "        x = x.copy()\n",
      "        ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get morph matrix 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xxc90/neutronNoise_paper/PFSA.py:573: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"cal_morph_matrix\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /home/xxc90/neutronNoise_paper/PFSA.py (581)\n",
      "\n",
      "File \"PFSA.py\", line 581:\n",
      "    def cal_morph_matrix(self, x, states_size, regime='MAP'):\n",
      "        <source elided>\n",
      "        # print(series_lens)\n",
      "        x = x.copy()\n",
      "        ^\n",
      "\n",
      "  @numba.jit(boundscheck=True)\n",
      "/home/xxc90/neutronNoise_paper/PFSA.py:573: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"cal_morph_matrix\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"PFSA.py\", line 590:\n",
      "    def cal_morph_matrix(self, x, states_size, regime='MAP'):\n",
      "        <source elided>\n",
      "\n",
      "        for m in range(x_m):\n",
      "        ^\n",
      "\n",
      "  @numba.jit(boundscheck=True)\n",
      "/home/xxc90/.local/lib/python3.8/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"cal_morph_matrix\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"PFSA.py\", line 581:\n",
      "    def cal_morph_matrix(self, x, states_size, regime='MAP'):\n",
      "        <source elided>\n",
      "        # print(series_lens)\n",
      "        x = x.copy()\n",
      "        ^\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/xxc90/.local/lib/python3.8/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"PFSA.py\", line 581:\n",
      "    def cal_morph_matrix(self, x, states_size, regime='MAP'):\n",
      "        <source elided>\n",
      "        # print(series_lens)\n",
      "        x = x.copy()\n",
      "        ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get morph matrix 1.000000\n",
      "class 0.000000, calculate the left eigenvector corresponding to left eigenvalue 1, this is the state probability vector.\n",
      "class 0.000000, calculate the right eigenvectors corresponding to right eigenvalue (excludes eigen value 1).\n",
      "class 1.000000, calculate the left eigenvector corresponding to left eigenvalue 1, this is the state probability vector.\n",
      "class 1.000000, calculate the right eigenvectors corresponding to right eigenvalue (excludes eigen value 1).\n",
      "class 0.000000, calculate state weight Chi\n",
      "class 0.000000, calculate projection matrix 1\n",
      "class 0.000000, calculate projection matrix 2\n",
      "class 1.000000, calculate state weight Chi\n",
      "class 1.000000, calculate projection matrix 1\n",
      "class 1.000000, calculate projection matrix 2\n",
      "class 0\n",
      "normalization\n"
     ]
    }
   ],
   "source": [
    "depth = 1\n",
    "n_partitioning = 50\n",
    "normalizaiton_method = 'mixed classes'\n",
    "classfiers = ['projection 2']\n",
    "model = PFSA(n_partitioning = n_partitioning, depth = depth, train_regime= normalizaiton_method)\n",
    "model.fit(X_train, Y_train)\n",
    "y_test_predicted = model.predict(X_test, classifier=classfiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax0 = plt.subplots(1, 1, figsize=(3., 2.5))\n",
    "\n",
    "#axs[0].text(9000, 0.2, t1, ha=\"left\", rotation=90, wrap=False, fontsize=8)\n",
    "\n",
    "ax0.set_xlabel(\"Time [seconds]\")\n",
    "\n",
    "#axs[0].vlines([9000], 0, 1, transform=axs[0].get_xaxis_transform(), linewidth=0.3, color=\"r\")\n",
    "ax0.vlines([9000], 0, 1, transform=ax0.get_xaxis_transform(), linewidth=0.5, color=\"r\")\n",
    "ax0.plot(model.distances_cl['projection 2'][:,0], ':', color= 'g', zorder=-2, label = 'Normal')\n",
    "ax0.plot(model.distances_cl['projection 2'][:,1], color = 'b', zorder=-1, label = 'Anomalous')\n",
    "ax0.set_ylabel(\"Residual errors\")\n",
    "ax0.set_ylim([0.01,0.06])\n",
    "ax0.legend(frameon=False, loc=2, prop={'size': 7})\n",
    "#t1 = (\"Anomaly occurs\")\n",
    "#axs[0].text(9000, 0.02, t1, ha=\"left\", rotation=90, wrap=True, fontsize=8, zorder = 100 )\n",
    "#ax0_1.text(9000, 0.03, t1, ha=\"left\", rotation=90, wrap=True, fontsize=8 , zorder = 100 )\n",
    "ax0_1 = ax0.twinx()\n",
    "ax0_1.plot(y_test_predicted[:,3],  'x', color=\"k\", zorder = 0)\n",
    "ax0_1.set_ylabel(\"Predicted classes\")\n",
    "ax0_1.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"online_prediction_a.png\", bbox_inches = \"tight\",\n",
    "    pad_inches = 0, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax0 = plt.subplots(1, 1, figsize=(3., 2.5))\n",
    "\n",
    "#axs[0].text(9000, 0.2, t1, ha=\"left\", rotation=90, wrap=False, fontsize=8)\n",
    "\n",
    "ax0.set_xlabel(\"Time [seconds]\")\n",
    "\n",
    "#axs[0].vlines([9000], 0, 1, transform=axs[0].get_xaxis_transform(), linewidth=0.3, color=\"r\")\n",
    "ax0.vlines([9000], 0, 1, transform=ax0.get_xaxis_transform(), linewidth=0.5, color=\"r\")\n",
    "ax0.plot(model.distances_cl['projection 2'][:,0], ':', color= 'g', zorder=-2, label = 'Normal')\n",
    "ax0.plot(model.distances_cl['projection 2'][:,1], color = 'b', zorder=-1, label = 'Anomalous')\n",
    "ax0.set_ylabel(\"Residual errors\")\n",
    "ax0.set_ylim([0.03,0.035])\n",
    "ax0.legend(frameon=False, loc=2, prop={'size': 7})\n",
    "#t1 = (\"Anomaly occurs\")\n",
    "#axs[0].text(9000, 0.02, t1, ha=\"left\", rotation=90, wrap=True, fontsize=8, zorder = 100 )\n",
    "#ax0_1.text(9000, 0.03, t1, ha=\"left\", rotation=90, wrap=True, fontsize=8 , zorder = 100 )\n",
    "ax0_1 = ax0.twinx()\n",
    "ax0_1.plot(y_test_predicted[:,3],  'x', color=\"k\", zorder = 0)\n",
    "ax0_1.set_ylabel(\"Predicted classes\")\n",
    "ax0_1.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax0.set_xlim([9515,9535])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"online_prediction_b.png\", bbox_inches = \"tight\",\n",
    "    pad_inches = 0, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-adelaide",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
